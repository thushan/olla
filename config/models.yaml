# Olla Model Unification Configuration
# This configuration file defines how to unify model names, families, and capabilities
# across different LLM providers and formats.
version: "1.0"
model_extraction:
  family_patterns:
    - pattern: "^(mistral|mixtral)[-_]?(.+)"
      family_group: 1
      variant_group: 2
      description: "Mistral and Mixtral models"
      
    - pattern: "^(llama|gemma|phi|qwen)[-_]?(\d+(?:\.\d+)?)"
      family_group: 1
      variant_group: 2
      description: "Common families with version numbers"
      
    - pattern: "^[^/]+/(phi|llama|gemma|qwen|mistral)[-_]?(\d+(?:\.\d+)?)"
      family_group: 1
      variant_group: 2
      description: "Models with publisher prefix"
      
    - pattern: "^(codellama|starcoder|vicuna|falcon|yi)[-_]?(\d+[bB]?)"
      family_group: 1
      variant_group: 2
      description: "Code and specialised models"
      
    - pattern: "^(gpt)[-_]?(2|j|neox)?"
      family_group: 1
      variant_group: 2
      description: "GPT variants"
      
    - pattern: "^(deepseek)[-_]?(.+)?"
      family_group: 1
      variant_group: 2
      description: "DeepSeek models"

  # Maps architecture names to model families
  architecture_mappings:
    phi3: phi
    "phi3.5": phi
    phi4: phi
    llama: llama
    llama2: llama
    llama3: llama
    "llama3.1": llama
    "llama3.2": llama
    "llama3.3": llama
    gemma: gemma
    gemma2: gemma
    gemma3: gemma
    mistral: mistral
    mixtral: mixtral
    qwen: qwen
    qwen2: qwen
    "qwen2.5": qwen
    qwen3: qwen
    deepseek: deepseek
    yi: yi
    starcoder: starcoder
    codellama: codellama
    vicuna: vicuna
    falcon: falcon
    gpt2: gpt2
    gptj: gptj
    gptneox: gptneox
    bloom: bloom
    opt: opt
    mpt: mpt

  # Normalises family name variations
  family_aliases:
    llama3: llama
    "llama3.2": llama
    "llama3.3": llama
    llama4: llama
    gemma2: gemma
    gemma3: gemma
    phi3: phi
    "phi3.5": phi
    phi4: phi
    qwen2: qwen
    "qwen2.5": qwen
    qwen3: qwen
    deepseek2: deepseek
    devstral: mistral

  # Model famailies and their publishers
  publisher_mappings:
    llama: meta
    codellama: meta
    gemma: google
    phi: microsoft
    mistral: mistral
    mixtral: mistral
    qwen: alibaba
    yi: 01-ai
    deepseek: deepseek
    starcoder: bigcode
    falcon: tii
    vicuna: lmsys
    bloom: bigscience
    opt: meta
    gpt2: openai
    gptj: eleutherai
    gptneox: eleutherai

quantization:
  # Standardises quantisation formats
  mappings:
    # K-quants
    Q4_K_M: q4km
    Q4_K_S: q4ks
    Q3_K_L: q3kl
    Q3_K_M: q3km
    Q3_K_S: q3ks
    Q5_K_M: q5km
    Q5_K_S: q5ks
    Q6_K: q6k
    Q2_K: q2k
    
    # Standard quants
    Q4_0: q4
    Q4_1: q4_1
    Q5_0: q5
    Q5_1: q5_1
    Q8_0: q8
    
    # Float formats
    F16: f16
    FP16: f16
    F32: f32
    FP32: f32
    BF16: bf16
    
    # GPTQ and AWQ
    GPTQ_4BIT: gptq4
    GPTQ-4BIT: gptq4
    AWQ_4BIT: awq4
    AWQ-4BIT: awq4
    
    # Integer formats
    INT8: int8
    INT4: int4
    
    # Extended formats
    Q4_K_XL: q4kxl

capabilities:
  # Capabilities by model type
  type_capabilities:
    llm:
      - text-generation
      - chat
      - completion
    vlm:
      - text-generation
      - vision
      - multimodal
      - image-understanding
    embeddings:
      - embeddings
      - similarity
      - vector-search
    embedding:
      - embeddings
      - similarity
      - vector-search

  # Capabilities inferred from model names
  name_patterns:
    - pattern: "(code|coder|codegen|starcoder)"
      capabilities:
        - code-generation
        - programming
        - code-completion
        
    - pattern: "(instruct|chat|assistant)"
      capabilities:
        - instruction-following
        - chat
        
    - pattern: "(reasoning|think)"
      capabilities:
        - reasoning
        - logic
        
    - pattern: "(math|mathstral)"
      capabilities:
        - mathematics
        - problem-solving
        
    - pattern: "(vision|vlm|llava|bakllava)"
      capabilities:
        - vision
        - multimodal
        - image-understanding

  # Context length categories (in tokens)
  context_thresholds:
    extended_context: 32000
    long_context: 100000
    ultra_long_context: 1000000

special_rules:
  # Models that keep their original family names
  preserve_family:
    - nomic-bert
    - deepseek-coder-v2
    
  # Generic names that need architecture info
  generic_names:
    - model
    - unknown
    - test
    - temp
    - default